#!/usr/bin/env python3
"""
–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∫–Ω–∏–≥ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º - FB2, PDF, DOC
"""

from pathlib import Path
import json
import re
import xml.etree.ElementTree as ET
import csv
import pandas as pd
from datetime import datetime

class SalesBookProcessor:
    """–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –∫–Ω–∏–≥ –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º - –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–∏–∫–∏ –∏–∑ —Ä–∞–∑–Ω—ã—Ö —Ñ–æ—Ä–º–∞—Ç–æ–≤"""
    
    def __init__(self):
        self.books_dir = Path("books")
        self.data_dir = Path("data")
        self.data_dir.mkdir(exist_ok=True)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–µ—Ö–Ω–∏–∫ –ø—Ä–æ–¥–∞–∂
        self.technique_patterns = {
            '–≤—ã—è–≤–ª–µ–Ω–∏–µ_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π': [
                r'[–ê-–Ø–Å][^.!?]*(?:—á—Ç–æ|–∫–∞–∫|–ø–æ—á–µ–º—É|–∫–æ–≥–¥–∞|–≥–¥–µ|–∫–∞–∫–æ–π|–∫–∞–∫–∞—è|–∫–∞–∫–∏–µ)[^.!?]*\?',
                r'[–ê-–Ø–Å][^.!?]*(?:—Ä–∞—Å—Å–∫–∞–∂–∏—Ç–µ|–æ–±—ä—è—Å–Ω–∏—Ç–µ|–æ–ø–∏—à–∏—Ç–µ|–ø–æ–¥–µ–ª–∏—Ç–µ—Å—å)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–≤–∞–∂–Ω–æ|–∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç|–≤–æ–ª–Ω—É–µ—Ç|–±–µ—Å–ø–æ–∫–æ–∏—Ç)[^.!?]*\?',
                r'[–ê-–Ø–Å][^.!?]*(?:–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç|–Ω—É–∂–¥|—Ç—Ä–µ–±–æ–≤–∞–Ω)[^.!?]*[.!?]'
            ],
            '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è_–æ–±—ä–µ–∫—Ç–æ–≤': [
                r'[–ê-–Ø–Å][^.!?]*(?:—ç—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —á—Ç–æ|–±–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É|–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–ø—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ —Å–µ–±–µ|–ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ|–æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–≤—ã–≥–æ–¥–∞|–ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ|–ø–æ–ª—å–∑–∞)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–∫–≤–∞—Ä—Ç–∏—Ä–∞|–¥–æ–º|–æ–±—ä–µ–∫—Ç)[^.!?]*(?:—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫|–æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç)[^.!?]*[.!?]'
            ],
            '—Ä–∞–±–æ—Ç–∞_—Å_–≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏': [
                r'[–ê-–Ø–Å][^.!?]*(?:–ø–æ–Ω–∏–º–∞—é|—Å–æ–≥–ª–∞—Å–µ–Ω)[^.!?]*(?:–Ω–æ|–æ–¥–Ω–∞–∫–æ|—Ç–µ–º –Ω–µ –º–µ–Ω–µ–µ)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–≤–æ–∑—Ä–∞–∂–µ–Ω–∏–µ|—Å–æ–º–Ω–µ–Ω–∏–µ)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–¥–æ—Ä–æ–≥–æ)[^.!?]*[.!?]'
            ],
            '—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ_–¥–æ–≤–µ—Ä–∏—è': [
                r'[–ê-–Ø–Å][^.!?]*(?:–æ–ø—ã—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç|–ø—Ä–∞–∫—Ç–∏–∫–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–¥—Ä—É–≥–∏–µ –∫–ª–∏–µ–Ω—Ç—ã|–Ω–∞—à–∏ –∫–ª–∏–µ–Ω—Ç—ã)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–≥–∞—Ä–∞–Ω—Ç–∏—Ä—É—é|–æ–±–µ—â–∞—é|—Ä—É—á–∞—é—Å—å)[^.!?]*[.!?]',
                r'[–ê-–Ø–Å][^.!?]*(?:–¥–æ–≤–µ—Ä–∏–µ|–Ω–∞–¥–µ–∂–Ω–æ—Å—Ç—å)[^.!?]*[.!?]'
            ],
            '–∑–∞–∫—Ä—ã—Ç–∏–µ_—Å–¥–µ–ª–∫–∏': [
                r'[–ê-–Ø–Å][^.!?]*(?:–≥–æ—Ç–æ–≤—ã|—Å–æ–≥–ª–∞—Å–Ω—ã)[^.!?]*(?:–ø–æ–¥–ø–∏—Å–∞—Ç—å|–æ—Ñ–æ—Ä–º–∏—Ç—å|–∫—É–ø–∏—Ç—å)[^.!?]*\?',
                r'[–ê-–Ø–Å][^.!?]*(?:–∫–æ–≥–¥–∞ —É–¥–æ–±–Ω–æ|–∫–æ–≥–¥–∞ –≤–∞–º –ø–æ–¥—Ö–æ–¥–∏—Ç)[^.!?]*\?',
                r'[–ê-–Ø–Å][^.!?]*(?:–≤—ã–±–∏—Ä–∞–µ—Ç–µ|–ø—Ä–∏–Ω–∏–º–∞–µ—Ç–µ —Ä–µ—à–µ–Ω–∏–µ)[^.!?]*\?'
            ]
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤
        self.dialog_patterns = [
            r'(?:–ú–µ–Ω–µ–¥–∂–µ—Ä|–ü—Ä–æ–¥–∞–≤–µ—Ü|–†–∏–µ–ª—Ç–æ—Ä|–ê–≥–µ–Ω—Ç):\s*([^.!?]+[.!?])',
            r'(?:–ö–ª–∏–µ–Ω—Ç|–ü–æ–∫—É–ø–∞—Ç–µ–ª—å|–ó–∞–∫–∞–∑—á–∏–∫):\s*([^.!?]+[.!?])',
            r'‚Äî\s*([–ê-–Ø–Å][^.!?]+[.!?])'
        ]
    
    def process_all_books(self):
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–Ω–∏–≥–∏ –≤ –ø–∞–ø–∫–µ books (FB2, PDF, DOC) –∏ –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–∏–∫–∏ –ø—Ä–æ–¥–∞–∂"""
        all_techniques = []
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–∞–π–ª—ã
        supported_extensions = ["*.fb2", "*.pdf", "*.doc", "*.docx"]
        all_files = []
        
        for ext in supported_extensions:
            all_files.extend(list(self.books_dir.glob(ext)))
        
        if not all_files:
            print("‚ùå –ö–Ω–∏–≥–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –ø–∞–ø–∫–µ books/")
            return []
        
        print(f"üìö –ù–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: {len(all_files)}")
        print(f"   FB2: {len(list(self.books_dir.glob('*.fb2')))}")
        print(f"   PDF: {len(list(self.books_dir.glob('*.pdf')))}")
        print(f"   DOC: {len(list(self.books_dir.glob('*.doc*')))}")
        
        for book_file in all_files:
            print(f"üìñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {book_file.name}")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ñ–æ—Ä–º–∞—Ç–∞
            text = self.extract_text_from_file(book_file)
            
            if not text:
                print(f"   ‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ç–µ–∫—Å—Ç")
                continue
            
            # –ò—â–µ–º —Ç–µ—Ö–Ω–∏–∫–∏
            book_techniques = self.extract_techniques(text, book_file.name)
            all_techniques.extend(book_techniques)
            
            print(f"   ‚úÖ –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Ö–Ω–∏–∫: {len(book_techniques)}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –¥–µ–º–æ —Ç–µ—Ö–Ω–∏–∫–∏ –¥–ª—è –±–∞–∑–æ–≤–æ–π —Ç–µ–æ—Ä–∏–∏ (—Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑)
        demo_techniques = self.get_demo_techniques()
        all_techniques.extend(demo_techniques)
        print(f"üìù –î–æ–±–∞–≤–ª–µ–Ω–æ –±–∞–∑–æ–≤—ã—Ö —Ç–µ—Ö–Ω–∏–∫: {len(demo_techniques)}")
        
        return all_techniques
    
    def extract_text_from_file(self, file_path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –µ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞"""
        file_extension = file_path.suffix.lower()
        
        try:
            if file_extension == '.fb2':
                return self.extract_fb2_text(file_path)
            elif file_extension == '.pdf':
                return self.extract_pdf_text(file_path)
            elif file_extension in ['.doc', '.docx']:
                return self.extract_doc_text(file_path)
            else:
                print(f"   ‚ö†Ô∏è –ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–π —Ñ–æ—Ä–º–∞—Ç: {file_extension}")
                return ""
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {e}")
            return ""
    
    def extract_fb2_text(self, fb2_path):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ FB2 —Ñ–∞–π–ª–∞"""
        methods = [
            ('xml_parse', self._xml_extract),
            ('regex_clean', self._regex_extract),
            ('binary_force', self._binary_extract)
        ]
        
        for method_name, method_func in methods:
            try:
                text = method_func(fb2_path)
                if text and len(text) > 1000:
                    return self.clean_text(text)
            except Exception:
                continue
        return ""

    def _xml_extract(self, fb2_path):
        """XML –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ"""
        tree = ET.parse(fb2_path)
        root = tree.getroot()
        
        paragraphs = []
        for elem in root.iter():
            if elem.tag and elem.tag.endswith('p') and elem.text:
                text = elem.text.strip()
                if len(text) > 10:
                    paragraphs.append(text)
        
        return '\n\n'.join(paragraphs)

    def _regex_extract(self, fb2_path):
        """Regex –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ"""
        for encoding in ['utf-8', 'cp1251', 'koi8-r']:
            try:
                with open(fb2_path, 'r', encoding=encoding) as f:
                    content = f.read()
                
                clean_text = re.sub(r'<[^>]*>', '\n', content)
                clean_text = re.sub(r'\n\s*\n', '\n\n', clean_text)
                
                if len(clean_text) > 2000:
                    return clean_text
            except:
                continue
        return ""

    def _binary_extract(self, fb2_path):
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ"""
        with open(fb2_path, 'rb') as f:
            raw_data = f.read()
        
        for encoding in ['utf-8', 'cp1251']:
            try:
                content = raw_data.decode(encoding, errors='ignore')
                clean_text = re.sub(r'<[^>]*>', '\n', content)
                if len(clean_text) > 2000:
                    return clean_text
            except:
                continue
        return ""
    
    def extract_pdf_text(self, pdf_path):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ PDF —Ñ–∞–π–ª–∞"""
        text = ""
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è PDF
        try:
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º PyPDF2
            import PyPDF2
            with open(pdf_path, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
            
            if len(text.strip()) > 100:
                return self.clean_text(text)
        except Exception:
            pass
        
        try:
            # –ï—Å–ª–∏ PyPDF2 –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, –ø—Ä–æ–±—É–µ–º pdfplumber
            import pdfplumber
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            
            if len(text.strip()) > 100:
                return self.clean_text(text)
        except Exception:
            pass
        
        # –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–æ, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç—É—é —Å—Ç—Ä–æ–∫—É
        return ""
    
    def extract_doc_text(self, doc_path):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–∑ DOC/DOCX —Ñ–∞–π–ª–∞"""
        text = ""
        
        # –î–ª—è DOCX —Ñ–∞–π–ª–æ–≤
        if doc_path.suffix.lower() == '.docx':
            try:
                from docx import Document
                doc = Document(doc_path)
                
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                
                return self.clean_text(text)
            except Exception as e:
                print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è DOCX: {e}")
        
        # –î–ª—è —Å—Ç–∞—Ä—ã—Ö DOC —Ñ–∞–π–ª–æ–≤ –ø—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–µ—Ç–æ–¥—ã
        else:
            try:
                # –ü—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ python-docx (–∏–Ω–æ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å .doc)
                from docx import Document
                doc = Document(doc_path)
                
                for paragraph in doc.paragraphs:
                    text += paragraph.text + "\n"
                
                if len(text.strip()) > 100:
                    return self.clean_text(text)
            except Exception:
                pass
            
            try:
                # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∫–∞–∫ —Ç–µ–∫—Å—Ç
                with open(doc_path, 'rb') as f:
                    raw_data = f.read()
                
                # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏
                for encoding in ['utf-8', 'cp1251', 'latin1']:
                    try:
                        text = raw_data.decode(encoding, errors='ignore')
                        # –û—á–∏—â–∞–µ–º –æ—Ç –º—É—Å–æ—Ä–∞
                        clean_text = re.sub(r'[^\w\s.,!?;:()\-¬´¬ª""‚Äû"‚Äû'']', ' ', text)
                        clean_text = re.sub(r'\s+', ' ', clean_text)
                        
                        if len(clean_text.strip()) > 1000:
                            return clean_text
                    except:
                        continue
            except Exception:
                pass
        
        return ""
    
    def extract_techniques(self, text, book_name):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ö–Ω–∏–∫–∏ –ø—Ä–æ–¥–∞–∂ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        techniques = []
        
        # –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences = re.split(r'[.!?]+', text)
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) < 20 or len(sentence) > 300:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—É—é –∫–∞—Ç–µ–≥–æ—Ä–∏—é —Ç–µ—Ö–Ω–∏–∫
            for category, patterns in self.technique_patterns.items():
                for pattern in patterns:
                    if re.search(pattern, sentence, re.IGNORECASE):
                        quality = self.assess_quality(sentence)
                        
                        techniques.append({
                            'book': book_name,
                            'category': category,
                            'source': 'extracted',
                            'quality': quality,
                            'sales_technique': sentence
                        })
                        break
                else:
                    continue
                break
        
        return techniques
    
    def get_demo_techniques(self):
        """–î–æ–±–∞–≤–ª—è–µ—Ç –±–∞–∑–æ–≤—ã–µ —Ç–µ—Ö–Ω–∏–∫–∏ –ø—Ä–æ–¥–∞–∂"""
        demo_techniques = [
            {'book': 'theory_base', 'category': '–≤—ã—è–≤–ª–µ–Ω–∏–µ_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π', 'source': 'theory', 'quality': 10, 'sales_technique': '–ß—Ç–æ –¥–ª—è –≤–∞—Å –≤–∞–∂–Ω–æ –ø—Ä–∏ –≤—ã–±–æ—Ä–µ –∫–≤–∞—Ä—Ç–∏—Ä—ã?'},
            {'book': 'theory_base', 'category': '–≤—ã—è–≤–ª–µ–Ω–∏–µ_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π', 'source': 'theory', 'quality': 10, 'sales_technique': '–†–∞—Å—Å–∫–∞–∂–∏—Ç–µ –æ –≤–∞—à–∏—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è—Ö –∫ –∂–∏–ª—å—é.'},
            {'book': 'theory_base', 'category': '–≤—ã—è–≤–ª–µ–Ω–∏–µ_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π', 'source': 'theory', 'quality': 10, 'sales_technique': '–ö–∞–∫–∏–µ —Ñ–∞–∫—Ç–æ—Ä—ã –≤–ª–∏—è—é—Ç –Ω–∞ –≤–∞—à–µ —Ä–µ—à–µ–Ω–∏–µ?'},
            {'book': 'theory_base', 'category': '–≤—ã—è–≤–ª–µ–Ω–∏–µ_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π', 'source': 'theory', 'quality': 10, 'sales_technique': '–ß—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –≤ –∏–¥–µ–∞–ª—å–Ω–æ–π –∫–≤–∞—Ä—Ç–∏—Ä–µ?'},
            {'book': 'theory_base', 'category': '–≤—ã—è–≤–ª–µ–Ω–∏–µ_–ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–µ–π', 'source': 'theory', 'quality': 10, 'sales_technique': '–ö–∞–∫ –≤—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç–µ —Å–≤–æ–π –Ω–æ–≤—ã–π –¥–æ–º?'},
            {'book': 'theory_base', 'category': '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è_–æ–±—ä–µ–∫—Ç–æ–≤', 'source': 'theory', 'quality': 10, 'sales_technique': '–≠—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—ã —Å—ç–∫–æ–Ω–æ–º–∏—Ç–µ —á–∞—Å –≤—Ä–µ–º–µ–Ω–∏ –∫–∞–∂–¥—ã–π –¥–µ–Ω—å.'},
            {'book': 'theory_base', 'category': '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è_–æ–±—ä–µ–∫—Ç–æ–≤', 'source': 'theory', 'quality': 10, 'sales_technique': '–ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–π –ø–ª–∞–Ω–∏—Ä–æ–≤–∫–µ –≤–∞—à–∞ —Å–µ–º—å—è –±—É–¥–µ—Ç —á—É–≤—Å—Ç–≤–æ–≤–∞—Ç—å —Å–µ–±—è –∫–æ–º—Ñ–æ—Ä—Ç–Ω–æ.'},
            {'book': 'theory_base', 'category': '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è_–æ–±—ä–µ–∫—Ç–æ–≤', 'source': 'theory', 'quality': 10, 'sales_technique': '–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ, –∫–∞–∫ –∑–¥–æ—Ä–æ–≤–æ –±—É–¥–µ—Ç –≤—Å—Ç—Ä–µ—á–∞—Ç—å —Ä–∞—Å—Å–≤–µ—Ç—ã –Ω–∞ —ç—Ç–æ–º –±–∞–ª–∫–æ–Ω–µ.'},
            {'book': 'theory_base', 'category': '–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è_–æ–±—ä–µ–∫—Ç–æ–≤', 'source': 'theory', 'quality': 10, 'sales_technique': '–≠—Ç–∞ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç—å –¥–∞–µ—Ç –≤–∞–º –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–æ –ø–µ—Ä–µ–¥ —Å–æ—Å–µ–¥—è–º–∏.'},
            {'book': 'theory_base', 'category': '—Ä–∞–±–æ—Ç–∞_—Å_–≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–ü–æ–Ω–∏–º–∞—é –≤–∞—à–∏ —Å–æ–º–Ω–µ–Ω–∏—è, –¥–∞–≤–∞–π—Ç–µ —Ä–∞–∑–±–µ—Ä–µ–º –¥–µ—Ç–∞–ª–∏.'},
            {'book': 'theory_base', 'category': '—Ä–∞–±–æ—Ç–∞_—Å_–≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–°–æ–≥–ª–∞—Å–µ–Ω, —Ü–µ–Ω–∞ –≤–∞–∂–Ω–∞, –Ω–æ –ø–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –Ω–∞ –≤—ã–≥–æ–¥—ã.'},
            {'book': 'theory_base', 'category': '—Ä–∞–±–æ—Ç–∞_—Å_–≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–ú–Ω–æ–≥–∏–µ –∫–ª–∏–µ–Ω—Ç—ã —Å–Ω–∞—á–∞–ª–∞ —Ç–∞–∫ –¥—É–º–∞—é—Ç, –Ω–æ –ø–æ—Ç–æ–º –ø–æ–Ω–∏–º–∞—é—Ç.'},
            {'book': 'theory_base', 'category': '—Ä–∞–±–æ—Ç–∞_—Å_–≤–æ–∑—Ä–∞–∂–µ–Ω–∏—è–º–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–≠—Ç–æ –≤–∞–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å, —Å–ø–∞—Å–∏–±–æ —á—Ç–æ –ø–æ–¥–Ω—è–ª–∏ –µ–≥–æ.'},
            {'book': 'theory_base', 'category': '—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ_–¥–æ–≤–µ—Ä–∏—è', 'source': 'theory', 'quality': 10, 'sales_technique': '–ú–æ–π –æ–ø—ã—Ç –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —ç—Ç–æ –ª—É—á—à–µ–µ —Ä–µ—à–µ–Ω–∏–µ.'},
            {'book': 'theory_base', 'category': '—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ_–¥–æ–≤–µ—Ä–∏—è', 'source': 'theory', 'quality': 10, 'sales_technique': '–î—Ä—É–≥–∏–µ –∫–ª–∏–µ–Ω—Ç—ã –æ—Å—Ç–∞–ª–∏—Å—å –æ—á–µ–Ω—å –¥–æ–≤–æ–ª—å–Ω—ã.'},
            {'book': 'theory_base', 'category': '—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ_–¥–æ–≤–µ—Ä–∏—è', 'source': 'theory', 'quality': 10, 'sales_technique': '–ì–∞—Ä–∞–Ω—Ç–∏—Ä—É—é, —á—Ç–æ –≤—ã –Ω–µ –ø–æ–∂–∞–ª–µ–µ—Ç–µ –æ –≤—ã–±–æ—Ä–µ.'},
            {'book': 'theory_base', 'category': '—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ_–¥–æ–≤–µ—Ä–∏—è', 'source': 'theory', 'quality': 10, 'sales_technique': '–ù–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–∞ —Ä—ã–Ω–∫–µ 15 –ª–µ—Ç.'},
            {'book': 'theory_base', 'category': '–∑–∞–∫—Ä—ã—Ç–∏–µ_—Å–¥–µ–ª–∫–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–ö–æ–≥–¥–∞ –≤–∞–º —É–¥–æ–±–Ω–æ –ø–æ–¥–ø–∏—Å–∞—Ç—å –¥–æ–≥–æ–≤–æ—Ä?'},
            {'book': 'theory_base', 'category': '–∑–∞–∫—Ä—ã—Ç–∏–µ_—Å–¥–µ–ª–∫–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–ì–æ—Ç–æ–≤—ã –æ—Ñ–æ—Ä–º–∏—Ç—å –±—Ä–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–µ–≥–æ–¥–Ω—è?'},
            {'book': 'theory_base', 'category': '–∑–∞–∫—Ä—ã—Ç–∏–µ_—Å–¥–µ–ª–∫–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–ß—Ç–æ –≤—ã–±–∏—Ä–∞–µ—Ç–µ - –ø–µ—Ä–≤—ã–π –≤–∞—Ä–∏–∞–Ω—Ç –∏–ª–∏ –≤—Ç–æ—Ä–æ–π?'},
            {'book': 'theory_base', 'category': '–∑–∞–∫—Ä—ã—Ç–∏–µ_—Å–¥–µ–ª–∫–∏', 'source': 'theory', 'quality': 10, 'sales_technique': '–ö–æ–≥–¥–∞ –ø–ª–∞–Ω–∏—Ä—É–µ—Ç–µ –≤—ä–µ–∑–∂–∞—Ç—å?'}
        ]
        return demo_techniques
    
    def assess_quality(self, text):
        """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ —Ç–µ—Ö–Ω–∏–∫–∏ –ø—Ä–æ–¥–∞–∂ –æ—Ç 1 –¥–æ 10"""
        quality = 5  # –±–∞–∑–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞
        
        # –ë–æ–Ω—É—Å—ã –∑–∞ –ø–æ–ª–µ–∑–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        if '?' in text:
            quality += 1  # –≤–æ–ø—Ä–æ—Å—ã –≤–∞–∂–Ω—ã
        if any(word in text.lower() for word in ['–≤—ã', '–≤–∞—à', '–≤–∞–º']):
            quality += 1  # –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∞—Ü–∏—è
        if len(text) > 50:
            quality += 1  # –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
        if any(word in text.lower() for word in ['–≤—ã–≥–æ–¥–∞', '–ø–æ–ª—å–∑–∞', '—ç–∫–æ–Ω–æ–º–∏—è']):
            quality += 1  # —Ñ–æ–∫—É—Å –Ω–∞ –≤—ã–≥–æ–¥–∞—Ö
        
        # –®—Ç—Ä–∞—Ñ—ã
        if len(text) < 30:
            quality -= 1  # —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
        if len(text) > 200:
            quality -= 1  # —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ
        
        return max(1, min(10, quality))
    
    def clean_text(self, text):
        """–û—á–∏—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –æ—Ç –ª–∏—à–Ω–∏—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
        # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏
        text = re.sub(r'<[^>]*>', ' ', text)
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        text = re.sub(r'\s+', ' ', text)
        # –£–±–∏—Ä–∞–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        text = re.sub(r'[^\w\s.,!?;:()\-¬´¬ª""‚Äû"‚Äû'']', ' ', text)
        return text.strip()
    
    def save_to_csv(self, techniques):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ—Ö–Ω–∏–∫–∏ –≤ CSV —Ñ–∞–π–ª"""
        csv_path = self.data_dir / "quality_techniques.csv"
        
        with open(csv_path, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['book', 'category', 'source', 'quality', 'sales_technique'])
            writer.writeheader()
            writer.writerows(techniques)
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤: {csv_path}")
        return csv_path
    
    def save_summary(self, techniques):
        """–°–æ–∑–¥–∞–µ—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–≤–æ–¥–∫—É –ø–æ —Ç–µ—Ö–Ω–∏–∫–∞–º"""
        summary = {
            'total_techniques': len(techniques),
            'categories': {},
            'books': {},
            'quality_stats': {
                'avg_quality': sum(t['quality'] for t in techniques) / len(techniques) if techniques else 0,
                'avg_length': sum(len(t['sales_technique']) for t in techniques) / len(techniques) if techniques else 0
            }
        }
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        for technique in techniques:
            category = technique['category']
            book = technique['book']
            
            summary['categories'][category] = summary['categories'].get(category, 0) + 1
            summary['books'][book] = summary['books'].get(book, 0) + 1
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–∫—É
        summary_path = self.data_dir / "quality_summary.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"üìã –°–≤–æ–¥–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤: {summary_path}")
        return summary


def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    print("üìö –û–ë–†–ê–ë–û–¢–ö–ê –í–°–ï–• –ö–ù–ò–ì –ü–û –ü–†–û–î–ê–ñ–ê–ú")
    print("=" * 50)
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    processor = SalesBookProcessor()
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∫–Ω–∏–≥–∏
    print("üîÑ –ó–∞–ø—É—Å–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫–Ω–∏–≥...")
    techniques = processor.process_all_books()
    
    if techniques:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        processor.save_to_csv(techniques)
        summary = processor.save_summary(techniques)
        
        print("\n" + "="*50)
        print("üìà –ö–†–ê–¢–ö–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        print(f"–í—Å–µ–≥–æ —Ç–µ—Ö–Ω–∏–∫: {len(techniques)}")
        print(f"–°—Ä–µ–¥–Ω—è—è –æ—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: {summary['quality_stats']['avg_quality']:.1f}/10")
        print(f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞: {summary['quality_stats']['avg_length']:.0f} —Å–∏–º–≤–æ–ª–æ–≤")
        print("\n–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:")
        for category, count in summary['categories'].items():
            print(f"  {category}: {count}")
        
        print("\n–ö–Ω–∏–≥–∏:")
        for book, count in summary['books'].items():
            if count > 0:
                print(f"  {book}: {count}")
    else:
        print("\n‚ùå –¢–µ—Ö–Ω–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ books/")


if __name__ == "__main__":
    main() 